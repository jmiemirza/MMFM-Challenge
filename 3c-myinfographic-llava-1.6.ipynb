{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3487212",
   "metadata": {},
   "source": [
    "# Infographics Understanding with Llava-NEXT and Structured Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6a6e10-6fb4-4675-b4ae-992b51e7f1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leloykun/anaconda3/envs/MMFM-Challenge/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import huggingface_hub\n",
    "from PIL import Image, ImageOps\n",
    "from PIL.Image import Image as PILImage\n",
    "from transformers import LlavaNextProcessor\n",
    "from transformers.image_processing_utils import select_best_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380920c-e657-47b0-9de0-54e08336d35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cd39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_FORMAT = \"<system_prompt> USER: <image>\\\\n<user> ASSISTANT: \"\n",
    "SYSTEM_PROMPT_FORMAT = \"\"\"You are an infographics explainer. You will receive an image as an input and you must answer the user's question based on the image. Be concise and limit responses to at most 3 sentences, preferably one sentence long. Respond in English. Output in the following json format: <json_format>.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de13f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-vicuna-13b-hf\")\n",
    "possible_resolutions = processor.image_processor.image_grid_pinpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fcd67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible_resolutions += [\n",
    "#     [672, 1008],\n",
    "#     [1008, 672],\n",
    "#     [1008, 1008],\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca6db93e-fc62-4319-883c-611747cedce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_pad_image(image: PILImage) -> PILImage:\n",
    "    best_resolution = select_best_resolution(image.size, possible_resolutions)\n",
    "    print(f\"{best_resolution = }\")\n",
    "    resized_image = ImageOps.cover(image, best_resolution)\n",
    "    resized_and_padded_image = ImageOps.pad(\n",
    "        resized_image,\n",
    "        best_resolution,\n",
    "        method=processor.image_processor.resample,\n",
    "        color=(255,255,255,0),\n",
    "    )\n",
    "    return resized_and_padded_image\n",
    "\n",
    "\n",
    "def encode_local_image(image_path, resize_and_pad: bool=True):\n",
    "    # load image\n",
    "    image = Image.open(image_path)\n",
    "    if \".gif\" in image_path:\n",
    "        image = image.convert(\"RGB\")\n",
    "    if resize_and_pad:\n",
    "        image = resize_and_pad_image(image)\n",
    "        print(f\"New size: {image.size}\")\n",
    "\n",
    "    # Convert the image to a base64 string\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")  # Use the appropriate format (e.g., JPEG, PNG)\n",
    "    base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "    # add string formatting required by the endpoint\n",
    "    image_string = f\"data:image/png;base64,{base64_image}\"\n",
    "\n",
    "    return image_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae63e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_title(image_path: str) -> str:\n",
    "    title = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    return title.replace(\"-\", \" \").replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96df3592-fc0a-421b-8a03-88e76aa537e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tool():\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"infographic_explainer_tool\",\n",
    "            \"description\": \"Infographic Explair Tool\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"1_reasoning\": {\"type\": \"string\"},\n",
    "                    \"2_answer\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Concise answer to the user question.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"1_reasoning\", \"2_answer\"],\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f33000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://bkliyhzstf7g5dyz.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "headers = {\n",
    "\t\"Accept\" : \"application/json\",\n",
    "\t\"Authorization\": f\"Bearer {huggingface_hub.get_token()}\",\n",
    "\t\"Content-Type\": \"application/json\" \n",
    "}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3adc673-89aa-42e0-856a-dc6bcbaced9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image_path, question, seed=0, max_length: int=100):\n",
    "    image_base64 = encode_local_image(image_path)\n",
    "    question_trimmed = question[len(\"<image>\\n\"):]\n",
    "    title = format_title(image_path)\n",
    "    print(f\"{title = } | {question_trimmed = }\")\n",
    "    tool = build_tool()\n",
    "\n",
    "    system_prompt = SYSTEM_PROMPT_FORMAT.replace(\n",
    "        \"<json_format>\",\n",
    "        json.dumps(tool[\"function\"][\"parameters\"][\"properties\"]),\n",
    "    )\n",
    "    prompt = (\n",
    "        PROMPT_FORMAT\n",
    "        .replace(\"<system_prompt>\", system_prompt)\n",
    "        .replace(\"<image>\", f\"![]({image_base64})\")\n",
    "        .replace(\"<user>\", f\"This infographics has the title {title}. {question_trimmed}\")\n",
    "    )\n",
    "    print(f\"{prompt = }\")\n",
    "\n",
    "    # This version of TGI uses an older version of Outlines\n",
    "    # which re-orders the keys in the JSON in alphabetical order.\n",
    "    # Hence the prefixes in the keys in the grammer\n",
    "    response = query({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"return_full_text\": False,\n",
    "            \"max_new_tokens\": 2048,\n",
    "            \"frequency_penalty\": 1,\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"presence_penalty\": 0,\n",
    "            \"grammar\": {\n",
    "                \"type\": \"json\",\n",
    "                \"value\": tool[\"function\"][\"parameters\"],\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    print(f\"{response = }\")\n",
    "\n",
    "    return json.loads(response[0][\"generated_text\"])[\"2_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d0f95-e0b1-4c12-8d9d-b9c495a594b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c314253-ca29-409d-94ee-83e2c252d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/raw_datasets/myinfographic/images/_53f9b07a43e61_w1500.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fbacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "image = resize_and_pad_image(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6a09f-0570-48f8-89d7-f271140d7060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_inference(\n",
    "    image_path,\n",
    "    \"<image>\\nWhat is the overall message conveyed by the different elements and quotes in the infographic?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538d93d-ac45-4aff-8300-93842565aff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a7cb6-948e-4b0e-be15-278a40898f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"myinfographic\"\n",
    "dataset_path = os.path.join(\"data/raw_datasets\", dataset_name, \"annot_wo_answer.json\")\n",
    "print(dataset_path)\n",
    "assert os.path.exists(dataset_path)\n",
    "\n",
    "df_data = pd.read_json(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "818b75ab-750c-46db-ac23-ea519a95c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p inference_results/llava-1-6-vicuna-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx = set()\n",
    "for idx, row in df_data.iterrows():\n",
    "    id = row[\"id\"]\n",
    "    answer_txt_path = f\"inference_results/llava-1-6-vicuna-13b-hf/{id}.txt\"\n",
    "\n",
    "    image_path = f\"data/raw_datasets/{dataset_name}/images/{row['image']}\"\n",
    "    question = row[\"conversations\"][0][\"value\"]\n",
    "\n",
    "    if os.path.exists(answer_txt_path):\n",
    "        continue\n",
    "    print(id, idx, question)\n",
    "    print(image_path)\n",
    "\n",
    "    try:\n",
    "        answer = run_inference(image_path, question)\n",
    "        print(f\"{answer = }\")\n",
    "        with open(answer_txt_path, \"w\") as f:\n",
    "            f.write(str(answer))\n",
    "    except Exception as e:\n",
    "        print(\">>>>>>> ERROR\", idx, row, e, \"<<<<<<<\")\n",
    "        failed_idx.add(idx)\n",
    "        raise e\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ab7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693366a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809412b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc68ddf-3d15-4c36-bc95-9d3e5a855323",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_data.iterrows():\n",
    "    id = row[\"id\"]\n",
    "    answer_txt_path = f\"inference_results/llava-1-6-vicuna-13b-hf/{id}.txt\"\n",
    "    if not os.path.exists(answer_txt_path):\n",
    "        failed_idx.add(idx)\n",
    "        continue\n",
    "\n",
    "    with open(answer_txt_path, \"r\") as f:\n",
    "        answer = f.read()\n",
    "\n",
    "    if len(answer) >= 50:\n",
    "        failed_idx.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d345b-d645-4712-b0aa-8e7b69862f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dbb13-977f-423e-abeb-d3acf887b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.iloc[list(failed_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ec922-28ad-4a87-b59b-2fe47310a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx_2 = set()\n",
    "for idx, row in df_data.iloc[list(failed_idx)].iterrows():\n",
    "    id = row[\"id\"]\n",
    "    answer_txt_path = f\"inference_results/llava-1-6-vicuna-13b-hf/{id}.txt\"\n",
    "    if os.path.exists(answer_txt_path):\n",
    "        os.remove(answer_txt_path)\n",
    "    print(id, idx)\n",
    "\n",
    "    image_path = f\"data/raw_datasets/{dataset_name}/images/{row['image']}\"\n",
    "    question = row[\"conversations\"][0][\"value\"]\n",
    "\n",
    "    try:\n",
    "        answer = run_inference(image_path, question, seed=42)\n",
    "        with open(answer_txt_path, \"w\") as f:\n",
    "            f.write(answer)\n",
    "    except Exception as e:\n",
    "        print(idx, row, e)\n",
    "        failed_idx_2.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc41de8-07ec-4f65-a626-9968d01d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ce9d2-2f1a-4282-bc16-d242b42a09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.iloc[220][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fcee5-aa2f-447e-b11b-286644feb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.iloc[220][\"conversations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7c344-8f1a-4bf7-8006-235f41b90a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
