{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef6dc66",
   "metadata": {},
   "source": [
    "# Chart Understanding with GPT-4o and Tool Use (aka Structured Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d65fa6",
   "metadata": {},
   "source": [
    "NOTE: NOT ELIGIBLE FOR USE IN THE CHALLENGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26863094-ae01-4324-a0dc-922d1735f713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6a6e10-6fb4-4675-b4ae-992b51e7f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361a76c-1633-477d-b14c-8a6350d314db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-<secret>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380920c-e657-47b0-9de0-54e08336d35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6db93e-fc62-4319-883c-611747cedce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_base64(image_path: str):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded_image = base64.b64encode(f.read())\n",
    "    return encoded_image.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664677b9-11cd-4e49-beac-fb31304eddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_chart_type(image_path: str) -> str:\n",
    "    image_path_parts = image_path.split(\"/\")\n",
    "    print(f\"{image_path_parts = }\")\n",
    "    if \"_vbar_\" in image_path_parts[-1]:\n",
    "        return \"Vertical Bar Chart\"\n",
    "    elif \"_hbar_\" in image_path_parts[-1]:\n",
    "        return \"Horizontal Bar Chart\"\n",
    "    elif \"_line_\" in image_path_parts[-1]:\n",
    "        return \"Line Chart\"\n",
    "    elif \"_sct_\" in image_path_parts[-1]:\n",
    "        return \"Scatter Plot\"\n",
    "    elif \"_pie_\" in image_path_parts[-1]:\n",
    "        return \"Pie Chart\"\n",
    "    else:\n",
    "        return \"Other Chart Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96df3592-fc0a-421b-8a03-88e76aa537e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tool():\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"chart_information_extraction_tool\",\n",
    "            \"description\": \"Extract information from a chart\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"categories\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"},\n",
    "                        \"description\": \"Categories in the chart. They are on the X-axis in vertical bar charts, line charts, and scatter plots. But they are on the Y-axis in horizontal bar charts.\",\n",
    "                    },\n",
    "                    \"groups\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"},\n",
    "                        \"description\": \"Groups of data having the same color in the chart. Can be found in the legend.\"\n",
    "                    },\n",
    "                    \"reasoning\": {\"type\": \"string\"},\n",
    "                    \"answer\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Concise answer to the user question.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"categories\", \"groups\", \"reasoning\", \"answer\"],\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95659208-a3c1-43d1-bad2-afe7e08bf11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a scientific chart explainer. You will receive an image with a chart in it as an input and you must answer the user's question based on the data from the chart. Be concise and don't yap. If you are uncertain, provide a range of possible answers. Output in json format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3adc673-89aa-42e0-856a-dc6bcbaced9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image_path, question, model=\"gpt-4o-2024-05-13\", seed=0):\n",
    "    image_base64 = convert_image_to_base64(image_path)\n",
    "    question_trimmed = question[len(\"<image>\\n\"):]\n",
    "    chart_type = infer_chart_type(image_path)\n",
    "    print(f\"{chart_type = } | {question_trimmed = }\")\n",
    "    tool = build_tool()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": SYSTEM_PROMPT,\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"This is a {chart_type}. {question}\",\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        ],\n",
    "        temperature = 1,\n",
    "        # max_tokens=256,\n",
    "        seed=seed,\n",
    "        top_p = 1,\n",
    "        frequency_penalty = 0,\n",
    "        presence_penalty = 0,\n",
    "        tools = [tool],\n",
    "        tool_choice = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\"name\": tool[\"function\"][\"name\"]},\n",
    "        },\n",
    "    )\n",
    "    response_args = response.choices[0].message.tool_calls[0].function.arguments\n",
    "    print(f\"{response_args = }\")\n",
    "    return json.loads(response_args)[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d0f95-e0b1-4c12-8d9d-b9c495a594b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c314253-ca29-409d-94ee-83e2c252d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/raw_datasets/mychart/images/133_vbar_01ac38ed852061cf4eac77cd85c402bb6c8c9dc26c5fd2071a12aeae98ec84a3_81.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6a09f-0570-48f8-89d7-f271140d7060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_inference(image_path, \"<image>\\nHow many deferred trust units were granted during the year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538d93d-ac45-4aff-8300-93842565aff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a7cb6-948e-4b0e-be15-278a40898f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mychart\"\n",
    "dataset_path = os.path.join(\"data/raw_datasets\", dataset_name, \"annot_wo_answer.json\")\n",
    "print(dataset_path)\n",
    "assert os.path.exists(dataset_path)\n",
    "\n",
    "df_data = pd.read_json(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "818b75ab-750c-46db-ac23-ea519a95c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p inference_results/gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d72941-14b2-4178-8635-68ccb5764afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx = set()\n",
    "for idx, row in df_data.iterrows():\n",
    "    id = row[\"id\"]\n",
    "    answer_txt_path = f\"inference_results/gpt-4o/{id}.txt\"\n",
    "    if os.path.exists(answer_txt_path):\n",
    "        continue\n",
    "    print(id, idx)\n",
    "\n",
    "    image_path = f\"data/raw_datasets/{dataset_name}/images/{row['image']}\"\n",
    "    question = row[\"conversations\"][0][\"value\"]\n",
    "\n",
    "    try:\n",
    "        answer = run_inference(image_path, question)\n",
    "        with open(answer_txt_path, \"w\") as f:\n",
    "            f.write(answer)\n",
    "    except Exception as e:\n",
    "        print(idx, row, e)\n",
    "        failed_idx.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a704a27-2df0-47d5-ae5e-7735b4484c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx = set(failed_idx)\n",
    "failed_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0aaa50-911b-447c-955d-dc39474db4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e4495-82b5-4284-91a5-a35cfd54bf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994279f-1fb5-4fac-be77-771ee8656738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cc68ddf-3d15-4c36-bc95-9d3e5a855323",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_data.iterrows():\n",
    "    id = row[\"id\"]\n",
    "    answer_txt_path = f\"inference_results/gpt-4o/{id}.txt\"\n",
    "    if not os.path.exists(answer_txt_path):\n",
    "        failed_idx.add(idx)\n",
    "        continue\n",
    "\n",
    "    with open(answer_txt_path, \"r\") as f:\n",
    "        answer = f.read()\n",
    "\n",
    "    if len(answer) >= 50:\n",
    "        failed_idx.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d345b-d645-4712-b0aa-8e7b69862f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dbb13-977f-423e-abeb-d3acf887b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.iloc[list(failed_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ec922-28ad-4a87-b59b-2fe47310a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx_2 = set()\n",
    "for idx, row in df_data.iloc[list(failed_idx)].iterrows():\n",
    "    id = row[\"id\"]\n",
    "    answer_txt_path = f\"inference_results/gpt-4o/{id}.txt\"\n",
    "    if os.path.exists(answer_txt_path):\n",
    "        os.remove(answer_txt_path)\n",
    "    print(id, idx)\n",
    "\n",
    "    image_path = f\"data/raw_datasets/{dataset_name}/images/{row['image']}\"\n",
    "    question = row[\"conversations\"][0][\"value\"]\n",
    "\n",
    "    try:\n",
    "        answer = run_inference(image_path, question, seed=42)\n",
    "        with open(answer_txt_path, \"w\") as f:\n",
    "            f.write(answer)\n",
    "    except Exception as e:\n",
    "        print(idx, row, e)\n",
    "        failed_idx_2.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc41de8-07ec-4f65-a626-9968d01d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_idx_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fcee5-aa2f-447e-b11b-286644feb4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
